{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f045b95-8c4c-4ef9-ac5d-721d3ab43eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49390d7-66f4-48e9-8d5a-9bb104ea992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (0.10.21)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (3.10.1)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (4.25.7)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from jax->mediapipe) (1.15.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Installing collected packages: opencv-python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\mahima joshi\\\\.conda\\\\envs\\\\mp_env\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\mahima joshi\\.conda\\envs\\mp_env\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Installing collected packages: opencv-python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\mahima joshi\\\\.conda\\\\envs\\\\mp_env\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7197f6a-b59e-4f4e-b808-a9a834856f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "# Initializing mediapipe pose class\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Setting up the Pose function\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.8, model_complexity=2)\n",
    "\n",
    "# Initializing mediapipe drawing class, useful for annotation\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4631b9-c51c-4fd4-921d-f17b12ae4909",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left_elbow_angle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 97\u001b[0m\n\u001b[0;32m     88\u001b[0m     right_knee_angle \u001b[38;5;241m=\u001b[39m calculateAngle(\n\u001b[0;32m     89\u001b[0m         landmarks[mp_pose\u001b[38;5;241m.\u001b[39mPoseLandmark\u001b[38;5;241m.\u001b[39mRIGHT_HIP\u001b[38;5;241m.\u001b[39mvalue],\n\u001b[0;32m     90\u001b[0m         landmarks[mp_pose\u001b[38;5;241m.\u001b[39mPoseLandmark\u001b[38;5;241m.\u001b[39mRIGHT_KNEE\u001b[38;5;241m.\u001b[39mvalue],\n\u001b[0;32m     91\u001b[0m         landmarks[mp_pose\u001b[38;5;241m.\u001b[39mPoseLandmark\u001b[38;5;241m.\u001b[39mRIGHT_ANKLE\u001b[38;5;241m.\u001b[39mvalue]\n\u001b[0;32m     92\u001b[0m     )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# --- T Pose ---\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;241m165\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[43mleft_elbow_angle\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m195\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;241m165\u001b[39m \u001b[38;5;241m<\u001b[39m right_elbow_angle \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m195\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;241m80\u001b[39m \u001b[38;5;241m<\u001b[39m left_shoulder_angle \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m110\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;241m80\u001b[39m \u001b[38;5;241m<\u001b[39m right_shoulder_angle \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m110\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;241m165\u001b[39m \u001b[38;5;241m<\u001b[39m left_knee_angle \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m195\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;241m165\u001b[39m \u001b[38;5;241m<\u001b[39m right_knee_angle \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m195\u001b[39m\n\u001b[0;32m    103\u001b[0m ):\n\u001b[0;32m    104\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT Pose\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    105\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'left_elbow_angle' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.4, model_complexity=1)\n",
    "\n",
    "# Open webcam\n",
    "video = cv2.VideoCapture(0)\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Could not open video source.\")\n",
    "    exit()\n",
    "\n",
    "cv2.namedWindow(\"Pose Detection\", cv2.WINDOW_NORMAL)\n",
    "video.set(3, 1280)\n",
    "video.set(4, 960)\n",
    "\n",
    "time1 = 0\n",
    "\n",
    "#  Angle Calculation \n",
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    x1, y1 = landmark1.x, landmark1.y\n",
    "    x2, y2 = landmark2.x, landmark2.y\n",
    "    x3, y3 = landmark3.x, landmark3.y\n",
    "\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) -\n",
    "                         math.atan2(y1 - y2, x1 - x2))\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    return angle\n",
    "    right_knee_angle = calculateAngle(\n",
    "            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "            landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
    "        )\n",
    "\n",
    "    if (\n",
    "        165 < left_elbow_angle < 195 and\n",
    "        165 < right_elbow_angle < 195 and\n",
    "        80 < left_shoulder_angle < 110 and\n",
    "        80 < right_shoulder_angle < 110 and\n",
    "        165 < left_knee_angle < 195 and\n",
    "        165 < right_knee_angle < 195\n",
    "    ):\n",
    "        label = 'T Pose'\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "# ---- Almost T Pose with feedback ----\n",
    "def classifyPose(landmarks, output_image, display=False):\n",
    "    label = \"Unknown Pose\"\n",
    "    feedback = \"\"\n",
    "    color = (0, 0, 255)\n",
    "\n",
    "    # --- Angle Calculations ---\n",
    "    left_elbow_angle = calculateAngle(\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "    )\n",
    "\n",
    "    right_elbow_angle = calculateAngle(\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
    "    )\n",
    "\n",
    "    left_shoulder_angle = calculateAngle(\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "    )\n",
    "\n",
    "    right_shoulder_angle = calculateAngle(\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value]\n",
    "    )\n",
    "\n",
    "    left_knee_angle = calculateAngle(\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "    )\n",
    "\n",
    "    right_knee_angle = calculateAngle(\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
    "    )\n",
    "\n",
    "\n",
    "# --- T Pose ---\n",
    "if (\n",
    "    165 < left_elbow_angle < 195 and\n",
    "    165 < right_elbow_angle < 195 and\n",
    "    80 < left_shoulder_angle < 110 and\n",
    "    80 < right_shoulder_angle < 110 and\n",
    "    165 < left_knee_angle < 195 and\n",
    "    165 < right_knee_angle < 195\n",
    "):\n",
    "    label = 'T Pose'\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "elif (\n",
    "    140 < left_elbow_angle < 210 and\n",
    "    140 < right_elbow_angle < 210 and\n",
    "    60 < left_shoulder_angle < 130 and\n",
    "    60 < right_shoulder_angle < 130\n",
    "):\n",
    "    label = 'Almost T Pose'\n",
    "    feedback_parts = []\n",
    "\n",
    "    if not (165 < left_elbow_angle < 195):\n",
    "        feedback_parts.append(\"Straighten left arm\")\n",
    "\n",
    "    if not (165 < right_elbow_angle < 195):\n",
    "        feedback_parts.append(\"Straighten right arm\")\n",
    "\n",
    "    if not (80 < left_shoulder_angle < 110):\n",
    "        feedback_parts.append(\"Adjust left shoulder level\")\n",
    "\n",
    "    if not (80 < right_shoulder_angle < 110):\n",
    "        feedback_parts.append(\"Adjust right shoulder level\")\n",
    "\n",
    "    if not (165 < left_knee_angle < 195):\n",
    "        feedback_parts.append(\"Straighten left leg\")\n",
    "\n",
    "    if not (165 < right_knee_angle < 195):\n",
    "        feedback_parts.append(\"Straighten right leg\")\n",
    "\n",
    "    feedback = ', '.join(feedback_parts)\n",
    "    color = (0, 165, 255)\n",
    "\n",
    "# --- Warrior II Pose ---\n",
    "elif (\n",
    "    (165 < left_elbow_angle < 195 or 165 < right_elbow_angle < 195) and\n",
    "    (80 < left_shoulder_angle < 110 and 80 < right_shoulder_angle < 110) and\n",
    "    ((165 < left_knee_angle < 195 and 90 < right_knee_angle < 120) or\n",
    "        (165 < right_knee_angle < 195 and 90 < left_knee_angle < 120))\n",
    "):\n",
    "    label = 'Warrior II Pose'\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "elif (\n",
    "    (150 < left_elbow_angle < 210 or 150 < right_elbow_angle < 210) and\n",
    "    (65 < left_shoulder_angle < 125 and 65 < right_shoulder_angle < 125)\n",
    "):\n",
    "    label = 'Almost Warrior II'\n",
    "    feedback = \"Adjust shoulder alignment and bend one knee forward more.\"\n",
    "    color = (0, 165, 255)\n",
    "\n",
    "# --- Tree Pose ---\n",
    "elif (\n",
    "    (165 < left_knee_angle < 195 or 165 < right_knee_angle < 195) and\n",
    "    (315 < left_knee_angle < 335 or 25 < right_knee_angle < 45)\n",
    "):\n",
    "    label = 'Tree Pose'\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "elif (\n",
    "    (140 < left_knee_angle < 200 or 140 < right_knee_angle < 200) and\n",
    "    (300 < left_knee_angle < 345 or 15 < right_knee_angle < 60)\n",
    "):\n",
    "    label = 'Almost Tree Pose'\n",
    "    feedback = \"Straighten standing leg, lift bent leg higher.\"\n",
    "    color = (0, 165, 255)\n",
    "\n",
    "# Thumbs Up Pose \n",
    "elif (\n",
    "    60 < right_elbow_angle < 100 and\n",
    "    landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y <\n",
    "    landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y and\n",
    "    70 < right_shoulder_angle < 120\n",
    "):\n",
    "    label = 'Thumbs Up Pose'\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "elif (\n",
    "    40 < right_elbow_angle < 120 and\n",
    "    landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y <\n",
    "    landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y\n",
    "):\n",
    "    label = 'Almost Thumbs Up'\n",
    "    feedback = \"Raise arm a bit more for clearer thumbs up.\"\n",
    "    color = (0, 165, 255)\n",
    "\n",
    "# --- Display Label and Feedback ---\n",
    "cv2.putText(output_image, label, (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "if feedback:\n",
    "    cv2.putText(output_image, feedback, (10, 60), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "\n",
    "return output_image, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18056431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pose Detection Function\n",
    "def detectPose(image, pose_model, display=False):\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose_model.process(rgb_image)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        return image, results.pose_landmarks.landmark\n",
    "    else:\n",
    "        return image, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b46d2bb-604b-403b-8815-af4e9b8e08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Real-time Loop ----\n",
    "while video.isOpened():\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    aspect_ratio = frame_width / frame_height\n",
    "    new_width = int(aspect_ratio * 640)\n",
    "    frame = cv2.resize(frame, (new_width, 640))\n",
    "\n",
    "    frame, landmarks = detectPose(frame, pose_video, display=False)\n",
    "\n",
    "    if landmarks is not None:\n",
    "        frame, _ = classifyPose(landmarks, frame, display=False)\n",
    "\n",
    "    time2 = time.time()\n",
    "    if (time2 - time1) > 0:\n",
    "        fps = 1.0 / (time2 - time1)\n",
    "        cv2.putText(frame, f'FPS: {int(fps)}', (10, 60),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 0), 2)\n",
    "    time1 = time2\n",
    "\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC key\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mp_env)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
